{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from titanicSurvival.constants import *\n",
    "from titanicSurvival.utils.common import  read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self,\n",
    "                 config_file_path= CONFIG_FILE_PATH,\n",
    "                 params_file_path= PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_file_path)\n",
    "        self.params = read_yaml(params_file_path)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "    def get_data_transformation(self) -> DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_tranformation_config = DataTransformationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            data_path=config.data_path,\n",
    "            \n",
    "        )\n",
    "        return data_tranformation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request as request\n",
    "import zipfile\n",
    "from titanicSurvival.logging import logger\n",
    "from titanicSurvival.utils.common import get_size\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OrdinalEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAgeSubSection(age):\n",
    "    #print(age)\n",
    "    if age > 60:\n",
    "        return 5\n",
    "    elif age > 50:\n",
    "        return 4\n",
    "    elif age > 40:\n",
    "        return 3\n",
    "    elif age > 30:\n",
    "        return 2\n",
    "    #elif age > 20:\n",
    "    #   return 2\n",
    "    elif age > 15:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def assignCabin(row):\n",
    "    if row.Cabin == 'X':\n",
    "        if row.Pclass == 1 :\n",
    "            return 'C'\n",
    "        elif row.Pclass == 2:\n",
    "            return 'F'\n",
    "        else:\n",
    "            return 'G'\n",
    "    else:\n",
    "        return row.Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformation:\n",
    "    def __init__(self,config:DataTransformationConfig):\n",
    "        self.config =config\n",
    "    \n",
    "    def combine_train_test_data(self):\n",
    "        try:\n",
    "            df = pd.read_csv(os.path.join('artifacts/data_ingestion/','train.csv'))\n",
    "            target_df = pd.read_csv(os.path.join('artifacts/data_ingestion/','gender_submission.csv'))\n",
    "            test_df = pd.read_csv(os.path.join('artifacts/data_ingestion/','test.csv'))\n",
    "            test_df.insert(1,'Survived',target_df['Survived'])\n",
    "            df = pd.concat([df, test_df])\n",
    "            logger.info(f\"Cocatenated train and test data\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    \n",
    "    \n",
    "    def create_features(self):\n",
    "\n",
    "        df = self.combine_train_test_data()\n",
    "        \n",
    "        df['Sex'] = df['Sex'].fillna(df['Sex'].mode()[0]).map({'female':0, 'male': 1 })\n",
    "        df['Age']=df['Age'].fillna(df['Age'].mode()[0])\n",
    "        df['Age']=df['Age'].apply(lambda x: getAgeSubSection(x))\n",
    "        df['Embarked']=df['Embarked'].fillna(df['Embarked'].mode()[0])\n",
    "        df['Embarked'] = (df['Embarked'].map({'C':0, 'S':1, 'Q':2})).astype(int)\n",
    "        \n",
    "        df['Cabin']=df.apply(lambda row: assignCabin(row),axis=1)\n",
    "\n",
    "\n",
    "        cabinEncode = OrdinalEncoder()\n",
    "        df['Cabin']=(cabinEncode.fit_transform(df[['Cabin']])).astype(int)\n",
    "        #print(df['Cabin'].isnull().sum())\n",
    "        df_np = df.to_numpy()\n",
    "\n",
    "        X_train,y_train = df_np[:-418,1:],df_np[:-418,0]\n",
    "        X_test,y_test = df_np[-418:,1:],df_np[-418:,0]\n",
    "\n",
    "        X_train_path = os.path.join(self.config.root_dir, 'train_features_x.csv')\n",
    "        pd.DataFrame(X_train).to_csv(X_train_path,index=False)\n",
    "\n",
    "        y_train_path = os.path.join(self.config.root_dir, 'train_features_y.csv')\n",
    "        pd.DataFrame(y_train).to_csv(y_train_path,index=False)\n",
    "\n",
    "        logger.info(f\"Train feature files created: {X_train_path} \\n and {y_train_path}\")\n",
    "        X_test_path = os.path.join(self.config.root_dir, 'test_features_x.csv')\n",
    "        pd.DataFrame(X_test).to_csv(X_test_path,index=False)\n",
    "\n",
    "        y_test_path = os.path.join(self.config.root_dir, 'test_features_y.csv')\n",
    "        pd.DataFrame(y_test).to_csv(y_test_path,index=False)\n",
    "        logger.info(f\"Test feature files created: {X_test_path} \\n and {y_test_path}\")\n",
    "\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-29 21:27:45,732: INFO: common: yaml file: config\\config.yaml loaded succesfully..]\n",
      "[2025-03-29 21:27:45,737: INFO: common: yaml file: params.yaml loaded succesfully..]\n",
      "[2025-03-29 21:27:45,741: INFO: common: Create Directory at :artifacts]\n",
      "[2025-03-29 21:27:45,746: INFO: common: Create Directory at :artifacts/data_transformation]\n",
      "[2025-03-29 21:27:45,777: INFO: 3684417095: Cocatenated train and test data]\n",
      "0\n",
      "[2025-03-29 21:27:45,961: INFO: 3684417095: Train feature files created: artifacts/data_transformation\\train_features_x.csv \n",
      " and artifacts/data_transformation\\train_features_y.csv]\n",
      "[2025-03-29 21:27:45,989: INFO: 3684417095: Test feature files created: artifacts/data_transformation\\test_features_x.csv \n",
      " and artifacts/data_transformation\\test_features_y.csv]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sri\\AppData\\Local\\Temp\\ipykernel_42224\\3684417095.py:32: RuntimeWarning: invalid value encountered in cast\n",
      "  df['Cabin']=(cabinEncode.fit_transform(df[['Cabin']])).astype(int)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    dat_transforamtion_config = config.get_data_transformation()\n",
    "    data_transformation = DataTransformation(config=dat_transforamtion_config)\n",
    "    data_transformation.create_features()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
